{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4143ba6c",
   "metadata": {},
   "source": [
    "## 7-2. 모델 크기 조절\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1fdcd1",
   "metadata": {},
   "source": [
    "### 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "def one_hot_encoding(data, dim=10000): # 아래 imdb.load_data의 num_words를 10000으로 설정할 예정이기 때문에 dim도 10000으로 맞춰줍니다.\n",
    "  results = np.zeros((len(data), dim))\n",
    "  for i, d in enumerate(data):\n",
    "    results[i, d] = 1.\n",
    "  return results\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "x_train = one_hot_encoding(train_data)\n",
    "x_test = one_hot_encoding(test_data)\n",
    "\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f5bca0",
   "metadata": {},
   "source": [
    "### ndarray의 element로 어떤 객체든지 올 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3344054c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(25000,)\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(train_data))\n",
    "print(train_data.shape)\n",
    "print(type(train_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbd6378",
   "metadata": {},
   "source": [
    "### 모델 구성 및 컴파일\n",
    "- optimizer : rmsprop\n",
    "- loss : binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed5c4d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (Dense)                (None, 128)               1280128   \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,296,769\n",
      "Trainable params: 1,296,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation='relu', input_shape=(10000, ), name='input'))\n",
    "model.add(layers.Dense(128, activation='relu', name='hidden'))\n",
    "model.add(layers.Dense(1, activation='sigmoid', name='output'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577a7629",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f57c2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4242 - accuracy: 0.8006"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=30,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77140f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(epochs, loss, 'b--', label='train_loss')\n",
    "ax1.plot(epochs, val_loss, 'r--', label='val_loss')\n",
    "ax1.set_title('Train and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "accuracy = history_dict['accuracy']\n",
    "val_accuracy = history_dict['val_accuracy']\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(epochs, accuracy, 'b--', label='train_accuracy')\n",
    "ax2.plot(epochs, val_accuracy, 'r--', label='val_accuracy')\n",
    "ax2.set_title('Train and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8497208",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_model = models.Sequential()\n",
    "b_model.add(layers.Dense(2048, activation='relu', input_shape=(10000, ), name='input3'))\n",
    "b_model.add(layers.Dense(2048, activation='relu', name='hidden3'))\n",
    "b_model.add(layers.Dense(1, activation='sigmoid', name='output3'))\n",
    "b_model.compile(optimizer='rmsprop',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "b_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "546fc74b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_461/3922054738.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m b_model_history = b_model.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m      2\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               validation_data=(x_test, y_test))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'b_model' is not defined"
     ]
    }
   ],
   "source": [
    "b_model_history = b_model.fit(x_train, y_train,\n",
    "                              epochs=30,\n",
    "                              batch_size=512, \n",
    "                              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807f99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_history_dict = b_model_history.history\n",
    "\n",
    "b_loss = b_history_dict['loss']\n",
    "b_val_loss = b_history_dict['val_loss']\n",
    "epochs = range(1, len(b_loss) + 1)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(epochs, b_loss, 'b-', label='train_loss(large)')\n",
    "ax1.plot(epochs, b_val_loss, 'r-', label='val_loss(large)')\n",
    "ax1.plot(epochs, loss, 'b--', label='train_loss')\n",
    "ax1.plot(epochs, val_loss, 'r--', label='val_loss')\n",
    "ax1.set_title('Train and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "b_accuracy = b_history_dict['accuracy']\n",
    "b_val_accuracy = b_history_dict['val_accuracy']\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(epochs, b_accuracy, 'b-', label='train_accuracy(large)')\n",
    "ax2.plot(epochs, b_val_accuracy, 'r-', label='val_accuracy(large)')\n",
    "ax2.plot(epochs, accuracy, 'b--', label='train_accuracy')\n",
    "ax2.plot(epochs, val_accuracy, 'r--', label='val_accuracy')\n",
    "ax2.set_title('Train and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561532bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_model = models.Sequential()\n",
    "s_model.add(layers.Dense(16, activation='relu', input_shape=(10000, ), name='input2'))\n",
    "s_model.add(layers.Dense(16, activation='relu', name='hidden2'))\n",
    "s_model.add(layers.Dense(1, activation='sigmoid', name='output2'))\n",
    "s_model.compile(optimizer='rmsprop',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "s_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f875fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_model_history = s_model.fit(x_train, y_train,\n",
    "                              epochs=30,\n",
    "                              batch_size=512, \n",
    "                              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a40fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_history_dict = s_model_history.history\n",
    "\n",
    "s_loss = s_history_dict['loss']\n",
    "s_val_loss = s_history_dict['val_loss']\n",
    "epochs = range(1, len(s_loss) + 1)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(epochs, b_loss, 'b-', label='train_loss(large)')\n",
    "ax1.plot(epochs, b_val_loss, 'r-', label='val_loss(large)')\n",
    "ax1.plot(epochs, loss, 'b--', label='train_loss')\n",
    "ax1.plot(epochs, val_loss, 'r--', label='val_loss')\n",
    "ax1.plot(epochs, s_loss, 'b:', label='train_loss(small)')\n",
    "ax1.plot(epochs, s_val_loss, 'r:', label='val_loss(small)')\n",
    "ax1.set_title('Train and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "s_accuracy = s_history_dict['accuracy']\n",
    "s_val_accuracy = s_history_dict['val_accuracy']\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(epochs, b_accuracy, 'b-', label='train_accuracy(large)')\n",
    "ax2.plot(epochs, b_val_accuracy, 'r-', label='val_accuracy(large)')\n",
    "ax2.plot(epochs, accuracy, 'b--', label='train_accuracy')\n",
    "ax2.plot(epochs, val_accuracy, 'r--', label='val_accuracy')\n",
    "ax2.plot(epochs, s_accuracy, 'b:', label='train_accuracy(small)')\n",
    "ax2.plot(epochs, s_val_accuracy, 'r:', label='val_accuracy(small)')\n",
    "ax2.set_title('Train and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [play ground]\n",
    "# 원하는 분은 Dense층을 늘리거나 줄이는 등 모델의 구조 역시 변경해보시기 바랍니다.\n",
    "\n",
    "your_model = models.Sequential()\n",
    "your_model.add(layers.Dense(4, activation='relu', input_shape=(10000, ), name='input2'))\n",
    "your_model.add(layers.Dense(4, activation='relu', name='hidden2'))\n",
    "your_model.add(layers.Dense(1, activation='sigmoid', name='output2'))\n",
    "your_model.compile(optimizer='rmsprop',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "your_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_model_history = your_model.fit(x_train, y_train, epochs=30, batch_size=512,  validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea7a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_history_dict = your_model_history.history\n",
    "\n",
    "your_loss = your_history_dict['loss']\n",
    "your_val_loss = your_history_dict['val_loss']\n",
    "epochs = range(1, len(your_loss) + 1)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(epochs, b_loss, 'b-', label='train_loss(large)')\n",
    "ax1.plot(epochs, b_val_loss, 'r-', label='val_loss(large)')\n",
    "ax1.plot(epochs, loss, 'b--', label='train_loss')\n",
    "ax1.plot(epochs, val_loss, 'r--', label='val_loss')\n",
    "ax1.plot(epochs, s_loss, 'b:', label='train_loss(small)')\n",
    "ax1.plot(epochs, s_val_loss, 'r:', label='val_loss(small)')\n",
    "ax1.plot(epochs, your_loss, 'g-', label='train_loss(your)')\n",
    "ax1.plot(epochs, your_val_loss, 'g--', label='val_loss(your)')\n",
    "ax1.set_title('Train and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "your_accuracy = your_history_dict['accuracy']\n",
    "your_val_accuracy = your_history_dict['val_accuracy']\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(epochs, b_accuracy, 'b-', label='train_accuracy(large)')\n",
    "ax2.plot(epochs, b_val_accuracy, 'r-', label='val_accuracy(large)')\n",
    "ax2.plot(epochs, accuracy, 'b--', label='train_accuracy')\n",
    "ax2.plot(epochs, val_accuracy, 'r--', label='val_accuracy')\n",
    "ax2.plot(epochs, s_accuracy, 'b:', label='train_accuracy(small)')\n",
    "ax2.plot(epochs, s_val_accuracy, 'r:', label='val_accuracy(small)')\n",
    "ax2.plot(epochs, your_accuracy, 'g-', label='train_accuracy(your)')\n",
    "ax2.plot(epochs, your_val_accuracy, 'g--', label='val_accuracy(your)')\n",
    "ax2.set_title('Train and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d20e170",
   "metadata": {},
   "source": [
    "## 규제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b28a48",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_461/1039054221.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml1_model\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m l1_model.add(layers.Dense(16, \n\u001b[1;32m      3\u001b[0m                           \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                           \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                           input_shape=(10000, )))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "l1_model =  models.Sequential()\n",
    "l1_model.add(layers.Dense(16, \n",
    "                          kernel_regularizer='l1',\n",
    "                          activation='relu', \n",
    "                          input_shape=(10000, )))\n",
    "l1_model.add(layers.Dense(16, \n",
    "                          kernel_regularizer='l1',\n",
    "                          activation='relu'))\n",
    "l1_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "l1_model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "l1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f2f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_model =  models.Sequential()\n",
    "l1_model.add(layers.Dense(16, \n",
    "                          kernel_regularizer='l1',\n",
    "                          activation='relu', \n",
    "                          input_shape=(10000, )))\n",
    "l1_model.add(layers.Dense(16, \n",
    "                          kernel_regularizer='l1',\n",
    "                          activation='relu'))\n",
    "l1_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "l1_model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "l1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1aa7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
